{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\software\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import hamming_loss,accuracy_score\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import hamming\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import silhouette_score,hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC_data=pd.read_csv(\"https://raw.githubusercontent.com/71sgupta/HW5_ML/master/Frogs_MFCCs.csv\")\n",
    "#MFCC_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 a) Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data : \n",
      "5036\n",
      "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
      "4519       1.0  0.133752  0.193796  0.556891  0.184403  0.071990 -0.129180   \n",
      "6395       1.0  0.493082  0.504096  0.246327  0.023502  0.175972  0.091741   \n",
      "6295       1.0  0.212997  0.303120  0.302054  0.152182  0.202291  0.125354   \n",
      "3463       1.0  0.167891  0.185879  0.546299  0.184312  0.058415 -0.098446   \n",
      "5736       1.0  0.514452  0.449875  0.272170  0.036705  0.123338  0.027606   \n",
      "\n",
      "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  \\\n",
      "4519 -0.017578  0.193294  0.082975  ...  0.211924 -0.079567 -0.191343   \n",
      "6395 -0.064137  0.066681  0.137811  ...  0.024912 -0.012978  0.025401   \n",
      "6295 -0.154379 -0.054431  0.105831  ...  0.121852  0.034841 -0.002391   \n",
      "3463 -0.032581  0.097713 -0.016290  ...  0.069935 -0.129639 -0.117241   \n",
      "5736 -0.030304  0.077557  0.062399  ...  0.057378 -0.001126  0.026482   \n",
      "\n",
      "      MFCCs_20  MFCCs_21  MFCCs_22           Family      Genus  \\\n",
      "4519 -0.133257  0.131264  0.240681  Leptodactylidae  Adenomera   \n",
      "6395 -0.010378 -0.050626  0.044555          Hylidae  Hypsiboas   \n",
      "6295  0.012819 -0.032602 -0.022817          Hylidae  Hypsiboas   \n",
      "3463 -0.043075  0.117741  0.178809  Leptodactylidae  Adenomera   \n",
      "5736 -0.005367 -0.003291  0.041080          Hylidae  Hypsiboas   \n",
      "\n",
      "                     Species  RecordID  \n",
      "4519  AdenomeraHylaedactylus        24  \n",
      "6395       HypsiboasCordobae        42  \n",
      "6295       HypsiboasCordobae        42  \n",
      "3463  AdenomeraHylaedactylus        21  \n",
      "5736       HypsiboasCordobae        40  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "Test Data : \n",
      "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
      "3167       1.0  0.123768  0.032897  0.429020  0.165992  0.034508 -0.101945   \n",
      "5875       1.0  0.218702  0.310872  0.259415  0.189971  0.151001 -0.039367   \n",
      "4271       1.0  0.140556  0.181561  0.560237  0.274503  0.111402 -0.140551   \n",
      "5132       1.0  0.751175  0.772045  0.341105 -0.265673  0.039649  0.249843   \n",
      "372        1.0  0.545229  0.603198  0.533603 -0.160986 -0.105968  0.407974   \n",
      "\n",
      "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  \\\n",
      "3167  0.007384  0.278345  0.150814  ...  0.282532  0.093757 -0.083552   \n",
      "5875 -0.106490  0.088320  0.072862  ... -0.035594 -0.000591  0.023568   \n",
      "4271 -0.009588  0.236096  0.020710  ...  0.180872 -0.134365 -0.169119   \n",
      "5132 -0.068178 -0.017349  0.207749  ...  0.109199 -0.068867 -0.112792   \n",
      "372   0.128612 -0.220269  0.123654  ...  0.021669  0.136926 -0.046798   \n",
      "\n",
      "      MFCCs_20  MFCCs_21  MFCCs_22           Family      Genus  \\\n",
      "3167 -0.138778  0.010718  0.257403  Leptodactylidae  Adenomera   \n",
      "5875  0.023032  0.007511  0.010549          Hylidae  Hypsiboas   \n",
      "4271 -0.058850  0.149404  0.175481  Leptodactylidae  Adenomera   \n",
      "5132  0.201221  0.120879 -0.146358          Hylidae  Hypsiboas   \n",
      "372  -0.095415  0.063379  0.011197  Leptodactylidae  Adenomera   \n",
      "\n",
      "                     Species  RecordID  \n",
      "3167  AdenomeraHylaedactylus        21  \n",
      "5875       HypsiboasCordobae        41  \n",
      "4271  AdenomeraHylaedactylus        24  \n",
      "5132    HypsiboasCinerascens        36  \n",
      "372           AdenomeraAndre         8  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "MFCC_train_data,MFCC_test_data=train_test_split(MFCC_data, test_size=0.3)\n",
    "print(\"Train Data : \")\n",
    "print(len(MFCC_train_data))\n",
    "print(MFCC_train_data.head())\n",
    "\n",
    "print(\"Test Data : \")\n",
    "print(MFCC_test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 b) i) Research exact match and hamming score/ loss methods for evaluating multi-label classification and use them in evaluating the classifiers in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exact Match : This method ignores partially correct(considering them incorrect) and extend the accuracy of single label case for multi-label prediction. This is called Exact Match Ratio\n",
    "\n",
    "##### Hamming Loss : It gives how many times relevance of an example to a class label is incorrectly predicted It takes into account the prediction error(incorrect label predicted) and the missing error(a relevant label is not predicted),normalized over total number of classes and total number of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 b(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-4])\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 20), \"gamma\": np.linspace(0.0001, 10, 10)}\n",
    "svm = SVC(kernel=\"rbf\",tol=0.1)\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "search.fit(X, np.ravel(y))\n",
    "res=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 54.55595\n",
      "The width of guassian is : 0.38729\n",
      "Hamming Loss for Family using guassian kernel and one vs rest classifier: 0.01065\n",
      "Exact Match score for Family using guassian kernel and one vs rest classifier: 0.98935\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res['C'],5)))\n",
    "print(\"The width of guassian is : \"+str(round(1/np.sqrt(2*res['gamma']),5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "y_test=MFCC_test_data.iloc[:,-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-4])\n",
    "#svm = SVC(kernel=\"rbf\",decision_function_shape='ovr',C=res['C'],gamma=res['gamma'])\n",
    "#svm.fit(X,np.ravel(y))\n",
    "pred=search.predict(X_test)\n",
    "hm_loss=hamming_loss(y_test,pred)\n",
    "acc_score=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Family using guassian kernel and one vs rest classifier: \"+str(round(hm_loss,5)))\n",
    "print(\"Exact Match score for Family using guassian kernel and one vs rest classifier: \"+str(round(acc_score,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-3])\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 20), \"gamma\": np.linspace(0.0001, 10, 10)}\n",
    "svm = SVC(kernel=\"rbf\",decision_function_shape='ovr')\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "search.fit(X, np.ravel(y))\n",
    "res1=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 54.55595\n",
      "The width of guassian is : 0.38729\n",
      "Hamming Loss for Genus using guassian kernel and one vs rest classifier: 0.01112\n",
      "Exact Match score for Genus using guassian kernel and one vs rest classifier: 0.98888\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res1['C'],5)))\n",
    "print(\"The width of guassian is : \"+str(round(1/np.sqrt(2*res1['gamma']),5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "y_test=MFCC_test_data.iloc[:,-3]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-3])\n",
    "svm = SVC(kernel=\"rbf\",decision_function_shape='ovr',C=res1['C'],gamma=res1['gamma'])\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss1=hamming_loss(y_test,pred)\n",
    "acc_score1=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Genus using guassian kernel and one vs rest classifier: \"+str(round(hm_loss1,5)))\n",
    "print(\"Exact Match score for Genus using guassian kernel and one vs rest classifier: \"+str(round(acc_score1,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-2])\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 20), \"gamma\": np.linspace(0.0001, 10, 10)}\n",
    "svm = SVC(kernel=\"rbf\",decision_function_shape='ovr')\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "search.fit(X, np.ravel(y))\n",
    "res2=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 6.15848\n",
      "The width of guassian is : 0.38729\n",
      "Hamming Loss for Species using guassian kernel and one vs rest classifier: 0.01112\n",
      "Exact Match score for Species using guassian kernel and one vs rest classifier: 0.98888\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res2['C'],5)))\n",
    "print(\"The width of guassian is : \"+str(round(1/np.sqrt(2*res2['gamma']),5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "y_test=MFCC_test_data.iloc[:,-2]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-2])\n",
    "svm = SVC(kernel=\"rbf\",decision_function_shape='ovr',C=res2['C'],gamma=res2['gamma'])\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss2=hamming_loss(y_test,pred)\n",
    "acc_score2=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Species using guassian kernel and one vs rest classifier: \"+str(round(hm_loss2,5)))\n",
    "print(\"Exact Match score for Species using guassian kernel and one vs rest classifier: \"+str(round(acc_score2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average hamming loss using guassian kernel and one vs rest classifier is : 0.01096\n",
      "The average exact match score using guassian kernel and one vs rest classifier is : 0.98904\n"
     ]
    }
   ],
   "source": [
    "avg_res=(hm_loss+hm_loss1+hm_loss2)/3\n",
    "avg_em=(acc_score+acc_score1+acc_score2)/3\n",
    "\n",
    "print(\"The average hamming loss using guassian kernel and one vs rest classifier is : \"+str(round(avg_res,5)))\n",
    "print(\"The average exact match score using guassian kernel and one vs rest classifier is : \"+str(round(avg_em,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 b(ii) After Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-4])\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 20), \"gamma\": np.linspace(0.0001, 10, 10)}\n",
    "svm = SVC(kernel=\"rbf\",decision_function_shape='ovr')\n",
    "\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "\n",
    "search.fit(X_scaled, np.ravel(y))\n",
    "res3=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 112883.78917\n",
      "The width of guassian is : 70.71068\n",
      "Hamming Loss for Family using guassian kernel and one vs rest classifier: 0.01621\n",
      "Exact Match score for Family using guassian kernel and one vs rest classifier: 0.98379\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res3['C'],5)))\n",
    "print(\"The width of guassian is : \"+str(round(1/np.sqrt(2*res3['gamma']),5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_test=MFCC_test_data.iloc[:,-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-4])\n",
    "svm = SVC(kernel=\"rbf\",decision_function_shape='ovr',C=res3['C'],gamma=res3['gamma'])\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss3=hamming_loss(y_test,pred)\n",
    "acc_score3=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Family using guassian kernel and one vs rest classifier: \"+str(round(hm_loss3,5)))\n",
    "print(\"Exact Match score for Family using guassian kernel and one vs rest classifier: \"+str(round(acc_score3,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-3])\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 20), \"gamma\": np.linspace(0.0001, 10, 10)}\n",
    "svm = SVC(kernel=\"rbf\",decision_function_shape='ovr')\n",
    "\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "\n",
    "search.fit(X_scaled, np.ravel(y))\n",
    "res4=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 335981.82863\n",
      "The width of guassian is : 70.71068\n",
      "Hamming Loss for Genus using guassian kernel and one vs rest classifier: 0.01482\n",
      "Exact Match score for Genus using guassian kernel and one vs rest classifier: 0.98518\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res4['C'],5)))\n",
    "print(\"The width of guassian is : \"+str(round(1/np.sqrt(2*res4['gamma']),5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_test=MFCC_test_data.iloc[:,-3]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-3])\n",
    "svm = SVC(kernel=\"rbf\",decision_function_shape='ovr',C=res4['C'],gamma=res4['gamma'])\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss4=hamming_loss(y_test,pred)\n",
    "acc_score4=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Genus using guassian kernel and one vs rest classifier: \"+str(round(hm_loss4,5)))\n",
    "print(\"Exact Match score for Genus using guassian kernel and one vs rest classifier: \"+str(round(acc_score4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-2])\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 20), \"gamma\": np.linspace(0.0001, 10, 10)}\n",
    "svm = SVC(kernel=\"rbf\",decision_function_shape='ovr')\n",
    "\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "\n",
    "search.fit(X_scaled, np.ravel(y))\n",
    "res5=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 112883.78917\n",
      "The width of guassian is : 70.71068\n",
      "Hamming Loss for Species using guassian kernel and one vs rest classifier: 0.02084\n",
      "Exact Match score for Species using guassian kernel and one vs rest classifier: 0.97916\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res5['C'],5)))\n",
    "print(\"The width of guassian is : \"+str(round(1/np.sqrt(2*res5['gamma']),5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_test=MFCC_test_data.iloc[:,-2]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-2])\n",
    "svm = SVC(kernel=\"rbf\",decision_function_shape='ovr',C=res5['C'],gamma=res5['gamma'])\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss5=hamming_loss(y_test,pred)\n",
    "acc_score5=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Species using guassian kernel and one vs rest classifier: \"+str(round(hm_loss5,5)))\n",
    "print(\"Exact Match score for Species using guassian kernel and one vs rest classifier: \"+str(round(acc_score5,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average hamming loss using guassian kernel and one vs rest classifier after standardization is : 0.01729\n",
      "The average exact match score using guassian kernel and one vs rest classifier after standardization is : 0.98271\n"
     ]
    }
   ],
   "source": [
    "avg_res=(hm_loss3+hm_loss4+hm_loss5)/3\n",
    "avg_em=(acc_score3+acc_score4+acc_score5)/3\n",
    "\n",
    "print(\"The average hamming loss using guassian kernel and one vs rest classifier after standardization is : \"+str(round(avg_res,5)))\n",
    "print(\"The average exact match score using guassian kernel and one vs rest classifier after standardization is : \"+str(round(avg_em,5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 b(iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-4])\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "params_dict = {\"C\": np.logspace(-3, 6,20)}\n",
    "svm = LinearSVC(penalty='l1',dual=False,max_iter=20000)\n",
    "\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "\n",
    "search.fit(X_scaled, np.ravel(y))\n",
    "res6=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 54.55595\n",
      "Hamming Loss for Family using l1 penalty: 0.06623\n",
      "Exact Match score for Family using l1 penalty: 0.93377\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res6['C'],5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_test=MFCC_test_data.iloc[:,-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-4])\n",
    "svm = LinearSVC(penalty='l1',C=res6['C'],dual=False,max_iter=20000)\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss6=hamming_loss(y_test,pred)\n",
    "acc_score6=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Family using l1 penalty: \"+str(round(hm_loss6,5)))\n",
    "print(\"Exact Match score for Family using l1 penalty: \"+str(round(acc_score6,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-3])\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 20)}\n",
    "svm = LinearSVC(penalty='l1',dual=False,max_iter=20000)\n",
    "\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "\n",
    "search.fit(X_scaled, np.ravel(y))\n",
    "res7=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 6.15848\n",
      "Hamming Loss for Genus using l1 penalty: 0.05373\n",
      "Exact Match score for Genus using l1 penalty: 0.94627\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res7['C'],5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_test=MFCC_test_data.iloc[:,-3]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-3])\n",
    "svm = LinearSVC(penalty='l1',C=res7['C'],dual=False,max_iter=20000)\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss7=hamming_loss(y_test,pred)\n",
    "acc_score7=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Genus using l1 penalty: \"+str(round(hm_loss7,5)))\n",
    "print(\"Exact Match score for Genus using l1 penalty: \"+str(round(acc_score7,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-2])\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 20)}\n",
    "svm = LinearSVC(penalty='l1',dual=False,max_iter=20000)\n",
    "\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "\n",
    "search.fit(X_scaled, np.ravel(y))\n",
    "res8=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 2.06914\n",
      "Hamming Loss for Species using l1 penalty: 0.04169\n",
      "Exact Match score for Species using l1 penalty: 0.95831\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res8['C'],5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_test=MFCC_test_data.iloc[:,-2]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-2])\n",
    "svm = LinearSVC(penalty='l1',C=res8['C'],dual=False,max_iter=20000)\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss8=hamming_loss(y_test,pred)\n",
    "acc_score8=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Species using l1 penalty: \"+str(round(hm_loss8,5)))\n",
    "print(\"Exact Match score for Species using l1 penalty: \"+str(round(acc_score8,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average hamming loss using l1 penalty is : 0.05388\n",
      "The average exact match score using l1 penalty is : 0.94612\n"
     ]
    }
   ],
   "source": [
    "avg_res=(hm_loss6+hm_loss7+hm_loss8)/3\n",
    "avg_em=(acc_score6+acc_score7+acc_score8)/3\n",
    "\n",
    "print(\"The average hamming loss using l1 penalty is : \"+str(round(avg_res,5)))\n",
    "print(\"The average exact match score using l1 penalty is : \"+str(round(avg_em,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 b(iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-4])\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "params_dict = {\"C\": np.logspace(-3,6,20)}\n",
    "svm = LinearSVC(penalty='l1',class_weight='balanced',dual=False,max_iter=20000)\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "search.fit(X_scaled, np.ravel(y))\n",
    "res9=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 2.06914\n",
      "Hamming Loss for Family using l1 penalty: 0.07272\n",
      "Exact Match score for Family using l1 penalty: 0.92728\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res9['C'],5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_test=MFCC_test_data.iloc[:,-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-4])\n",
    "svm = LinearSVC(penalty='l1',C=res9['C'],class_weight='balanced',dual=False,max_iter=20000)\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss9=hamming_loss(y_test,pred)\n",
    "acc_score9=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Family using l1 penalty: \"+str(round(hm_loss9,5)))\n",
    "print(\"Exact Match score for Family using l1 penalty: \"+str(round(acc_score9,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-3])\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "params_dict = {\"C\": np.logspace(-3,6,20)}\n",
    "svm = LinearSVC(penalty='l1',class_weight='balanced',dual=False,max_iter=20000)\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "search.fit(X_scaled, np.ravel(y))\n",
    "res10=search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 0.69519\n",
      "Hamming Loss for Genus using l1 penalty: 0.05604\n",
      "Exact Match score for Genus using l1 penalty: 0.94396\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res10['C'],5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_test=MFCC_test_data.iloc[:,-3]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-3])\n",
    "svm = LinearSVC(penalty='l1',C=res10['C'],class_weight='balanced',dual=False,max_iter=20000)\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss10=hamming_loss(y_test,pred)\n",
    "acc_score10=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Genus using l1 penalty: \"+str(round(hm_loss10,5)))\n",
    "print(\"Exact Match score for Genus using l1 penalty: \"+str(round(acc_score10,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-2])\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "params_dict = {\"C\": np.logspace(-3,6,20)}\n",
    "svm = LinearSVC(penalty='l1',class_weight='balanced',dual=False,max_iter=20000)\n",
    "search = GridSearchCV(estimator=svm, param_grid=params_dict,cv=10)\n",
    "search.fit(X_scaled, np.ravel(y))\n",
    "res11=search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight for svm penalty is : 0.69519\n",
      "Hamming Loss for Species using l1 penalty: 0.04076\n",
      "Exact Match score for Species using l1 penalty: 0.95924\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight for svm penalty is : \"+str(round(res11['C'],5)))\n",
    "\n",
    "X=MFCC_train_data.iloc[:,:-4]\n",
    "X_test=MFCC_test_data.iloc[:,:-4]\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_test=MFCC_test_data.iloc[:,-2]\n",
    "y=pd.DataFrame(MFCC_train_data.iloc[:,-2])\n",
    "svm = LinearSVC(penalty='l1',C=res11['C'],class_weight='balanced',dual=False,max_iter=20000)\n",
    "svm.fit(X,np.ravel(y))\n",
    "pred=svm.predict(X_test)\n",
    "hm_loss11=hamming_loss(y_test,pred)\n",
    "acc_score11=accuracy_score(y_test,pred)\n",
    "print(\"Hamming Loss for Species using l1 penalty: \"+str(round(hm_loss11,5)))\n",
    "print(\"Exact Match score for Species using l1 penalty: \"+str(round(acc_score11,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average hamming loss using l1 penalty is : 0.05651\n",
      "The average exact match score using l1 penalty is : 0.94349\n"
     ]
    }
   ],
   "source": [
    "avg_res=(hm_loss9+hm_loss10+hm_loss11)/3\n",
    "avg_em=(acc_score9+acc_score10+acc_score11)/3\n",
    "\n",
    "print(\"The average hamming loss using l1 penalty is : \"+str(round(avg_res,5)))\n",
    "print(\"The average exact match score using l1 penalty is : \"+str(round(avg_em,5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After comparing all the trained classifiers we found that classifier with guassian kernel gave better results i.e high accuracy and low hamming loss as compared to the l1 penalized SVM .So the data is not linearly separable as we got higher accuracy with guassian kernels classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
      "0       1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
      "1       1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
      "2       1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
      "3       1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
      "4       1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
      "\n",
      "   MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  \\\n",
      "0 -0.150063 -0.171128  0.124676  ... -0.108351 -0.077623 -0.009568  0.057684   \n",
      "1 -0.222475 -0.207693  0.170883  ... -0.090974 -0.056510 -0.035303  0.020140   \n",
      "2 -0.242234 -0.219153  0.232538  ... -0.050691 -0.023590 -0.066722 -0.025083   \n",
      "3 -0.194347 -0.098181  0.270375  ... -0.136009 -0.177037 -0.130498 -0.054766   \n",
      "4 -0.265423 -0.172700  0.266434  ... -0.048885 -0.053074 -0.088550 -0.031346   \n",
      "\n",
      "   MFCCs_21  MFCCs_22           Family      Genus         Species  RecordID  \n",
      "0  0.118680  0.014038  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
      "1  0.082263  0.029056  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
      "2  0.099108  0.077162  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
      "3 -0.018691  0.023954  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
      "4  0.108610  0.079244  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "MFCC_data=pd.read_csv(\"https://raw.githubusercontent.com/71sgupta/HW5_ML/master/Frogs_MFCCs.csv\")\n",
    "print(MFCC_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value of K in k-means clustering using Silhouette is : 4\n"
     ]
    }
   ],
   "source": [
    "X=MFCC_data.iloc[:,:-4]\n",
    "best_k={}\n",
    "for i in range(2,51):\n",
    "    model=KMeans(n_clusters=i)\n",
    "    model.fit(X)\n",
    "    pred=model.predict(X)\n",
    "    sum=0\n",
    "    X_arr=np.array(X)\n",
    "    centroids=model.cluster_centers_\n",
    "\n",
    "    score=silhouette_score(X,pred)\n",
    "    best_k.update({i:score})\n",
    "values=list(best_k.values())\n",
    "max_val=max(values)\n",
    "max_ind=values.index(max_val)\n",
    "keys=list(best_k.keys())\n",
    "bestk=keys[max_ind]\n",
    "print(\"Best Value of K in k-means clustering using Silhouette is : \" +str(bestk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "The labels for the 1 cluster are : \n",
      "Family : Hylidae\n",
      "Genus : Hypsiboas\n",
      "Species : HypsiboasCordobae\n",
      " \n",
      "The labels for the 2 cluster are : \n",
      "Family : Leptodactylidae\n",
      "Genus : Adenomera\n",
      "Species : AdenomeraHylaedactylus\n",
      " \n",
      "The labels for the 3 cluster are : \n",
      "Family : Hylidae\n",
      "Genus : Hypsiboas\n",
      "Species : HypsiboasCinerascens\n",
      " \n",
      "The labels for the 4 cluster are : \n",
      "Family : Dendrobatidae\n",
      "Genus : Ameerega\n",
      "Species : Ameeregatrivittata\n"
     ]
    }
   ],
   "source": [
    "def most_frequent(List): \n",
    "    return max(set(List), key = List.count) \n",
    "  \n",
    "model=KMeans(n_clusters=bestk)\n",
    "model.fit(X)\n",
    "pred=model.predict(X)\n",
    "samples_in_cluster={}\n",
    "for i in range(0,bestk):\n",
    "    indexes=np.where(pred==i)[0]\n",
    "    samples_in_cluster.update({i:list(indexes)})\n",
    "family=MFCC_data.iloc[:,-4]\n",
    "genus=MFCC_data.iloc[:,-3]\n",
    "species=MFCC_data.iloc[:,-2]\n",
    "cluster_labels={}\n",
    "for i in range(0,bestk):\n",
    "    temp=[]\n",
    "    p=family[samples_in_cluster[i]]\n",
    "    q=genus[samples_in_cluster[i]]\n",
    "    r=species[samples_in_cluster[i]]\n",
    "    #print(len(p))\n",
    "    #print(samples_in_cluster[i])\n",
    "    p_freq=most_frequent(list(p))\n",
    "    q_freq=most_frequent(list(q))\n",
    "    r_freq=most_frequent(list(r))\n",
    "    temp.append(p_freq)\n",
    "    temp.append(q_freq)\n",
    "    temp.append(r_freq)\n",
    "  \n",
    "    cluster_labels.update({i:temp})\n",
    "#print(cluster_labels)\n",
    "\n",
    "for i in range(0,len(cluster_labels)):\n",
    "    print(\" \")\n",
    "    print(\"The labels for the \"+str(i+1)+\" cluster are : \")\n",
    "    print(\"Family : \"+str(cluster_labels[i][0]))\n",
    "    print(\"Genus : \"+str(cluster_labels[i][1]))\n",
    "    print(\"Species : \"+str(cluster_labels[i][2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 c)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average hamming loss/hamming distance is : 0.2224229789205482\n",
      "The average hamming score is : 0.7775770210794481\n"
     ]
    }
   ],
   "source": [
    "#hamming loss\n",
    "labels=MFCC_data.iloc[:,-4:-1]\n",
    "#print(labels)\n",
    "hm_loss=0\n",
    "hm_sc=0\n",
    "for i in range(0,bestk):\n",
    "    lb=(labels.iloc)[samples_in_cluster[i],:]\n",
    "    for j in samples_in_cluster[i]:\n",
    "        hm_loss=hm_loss+hamming_loss(labels.iloc[j,:],cluster_labels[i])\n",
    "        hm_sc=hm_sc+accuracy_score(labels.iloc[j,:],cluster_labels[i])\n",
    "print(\"The average hamming loss/hamming distance is : \"+str(hm_loss/len(labels)))\n",
    "print(\"The average hamming score is : \"+str(hm_sc/len(labels)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte carlo- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo=[]\n",
    "monte_carlo_score=[]\n",
    "for mc in range(1,51):\n",
    "    X=MFCC_data.iloc[:,:-4]\n",
    "    best_k={}\n",
    "    for i in range(2,51):\n",
    "        model=KMeans(n_clusters=i,random_state=5)\n",
    "        model.fit(X)\n",
    "        pred=model.predict(X)\n",
    "        sum=0\n",
    "        X_arr=np.array(X)\n",
    "        centroids=model.cluster_centers_\n",
    "\n",
    "        score=silhouette_score(X,pred)\n",
    "        best_k.update({i:score})\n",
    "    values=list(best_k.values())\n",
    "    max_val=max(values)\n",
    "    max_ind=values.index(max_val)\n",
    "    keys=list(best_k.keys())\n",
    "    bestk=keys[max_ind]\n",
    "\n",
    "\n",
    "    def most_frequent(List): \n",
    "        return max(set(List), key = List.count) \n",
    "\n",
    "    model=KMeans(n_clusters=bestk)\n",
    "    model.fit(X)\n",
    "    pred=model.predict(X)\n",
    "    samples_in_cluster={}\n",
    "    for i in range(0,bestk):\n",
    "        indexes=np.where(pred==i)[0]\n",
    "        samples_in_cluster.update({i:list(indexes)})\n",
    "    family=MFCC_data.iloc[:,-4]\n",
    "    genus=MFCC_data.iloc[:,-3]\n",
    "    species=MFCC_data.iloc[:,-2]\n",
    "    cluster_labels={}\n",
    "    for i in range(0,bestk):\n",
    "        temp=[]\n",
    "        p=family[samples_in_cluster[i]]\n",
    "        q=genus[samples_in_cluster[i]]\n",
    "        r=species[samples_in_cluster[i]]\n",
    "        #print(len(p))\n",
    "        #print(samples_in_cluster[i])\n",
    "        p_freq=most_frequent(list(p))\n",
    "        q_freq=most_frequent(list(q))\n",
    "        r_freq=most_frequent(list(r))\n",
    "        temp.append(p_freq)\n",
    "        temp.append(q_freq)\n",
    "        temp.append(r_freq)\n",
    "\n",
    "        cluster_labels.update({i:temp})\n",
    "    #print(cluster_labels)\n",
    "\n",
    "    #hamming loss\n",
    "    labels=MFCC_data.iloc[:,-4:-1]\n",
    "    #print(labels)\n",
    "    hm_loss=0\n",
    "    hm_score=0\n",
    "    for i in range(0,bestk):\n",
    "        lb=(labels.iloc)[samples_in_cluster[i],:]\n",
    "        for j in samples_in_cluster[i]:\n",
    "            hm_loss=hm_loss+hamming_loss(labels.iloc[j,:],cluster_labels[i])\n",
    "            \n",
    "            hm_score=hm_score+accuracy_score(labels.iloc[j,:],cluster_labels[i])\n",
    "    #print(\"The average hamming loss is : \"+str(hm_loss/len(labels)))\n",
    "    ls=(hm_loss/len(labels))\n",
    "    monte_carlo.append(ls)\n",
    "    monte_carlo_score.append(hm_score/len(labels))\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming distances ,loss and scores after running 50 times :\n",
      "    Hamming Distances/Hamming Loss  Hamming Score\n",
      "0                         0.222423       0.777577\n",
      "1                         0.222423       0.777577\n",
      "2                         0.222423       0.777577\n",
      "3                         0.222423       0.777577\n",
      "4                         0.233634       0.766366\n",
      "5                         0.233356       0.766644\n",
      "6                         0.222423       0.777577\n",
      "7                         0.222423       0.777577\n",
      "8                         0.222423       0.777577\n",
      "9                         0.222423       0.777577\n",
      "10                        0.245263       0.754737\n",
      "11                        0.233356       0.766644\n",
      "12                        0.222423       0.777577\n",
      "13                        0.245263       0.754737\n",
      "14                        0.222284       0.777716\n",
      "15                        0.222284       0.777716\n",
      "16                        0.222423       0.777577\n",
      "17                        0.222423       0.777577\n",
      "18                        0.222423       0.777577\n",
      "19                        0.222423       0.777577\n",
      "20                        0.222423       0.777577\n",
      "21                        0.222423       0.777577\n",
      "22                        0.222423       0.777577\n",
      "23                        0.222423       0.777577\n",
      "24                        0.245263       0.754737\n",
      "25                        0.222423       0.777577\n",
      "26                        0.222423       0.777577\n",
      "27                        0.222423       0.777577\n",
      "28                        0.221774       0.778226\n",
      "29                        0.222284       0.777716\n",
      "30                        0.221774       0.778226\n",
      "31                        0.222423       0.777577\n",
      "32                        0.221913       0.778087\n",
      "33                        0.221913       0.778087\n",
      "34                        0.222423       0.777577\n",
      "35                        0.222423       0.777577\n",
      "36                        0.222423       0.777577\n",
      "37                        0.222423       0.777577\n",
      "38                        0.222423       0.777577\n",
      "39                        0.222423       0.777577\n",
      "40                        0.222423       0.777577\n",
      "41                        0.222423       0.777577\n",
      "42                        0.222423       0.777577\n",
      "43                        0.222423       0.777577\n",
      "44                        0.221913       0.778087\n",
      "45                        0.222423       0.777577\n",
      "46                        0.221774       0.778226\n",
      "47                        0.222284       0.777716\n",
      "48                        0.222423       0.777577\n",
      "49                        0.222423       0.777577\n",
      "The average of 50 Hamming Distances/hamming losses : 0.2243743340282613\n",
      "The standard deviation of 50 Hamming Distances/hamming losses : 0.005961608731157799\n",
      "\n",
      "The average of 50 Hamming Scores : 0.7756256659717389\n",
      "The standard deviation of 50 Hamming Scores : 0.005961608731157796\n"
     ]
    }
   ],
   "source": [
    "m_carlo_df=pd.concat([pd.DataFrame(monte_carlo),pd.DataFrame(monte_carlo_score)],axis=1)\n",
    "m_carlo_df.columns=['Hamming Distances/Hamming Loss','Hamming Score']\n",
    "print(\"Hamming distances ,loss and scores after running 50 times :\")\n",
    "print(m_carlo_df)\n",
    "stats=m_carlo_df.describe()\n",
    "print(\"The average of 50 Hamming Distances/hamming losses : \"+str(list(stats.iloc[1:2,0])[0]))\n",
    "print(\"The standard deviation of 50 Hamming Distances/hamming losses : \"+str(list(stats.iloc[2:3,0])[0]))\n",
    "print(\"\")\n",
    "print(\"The average of 50 Hamming Scores : \"+str(list(stats.iloc[1:2,1])[0]))\n",
    "print(\"The standard deviation of 50 Hamming Scores : \"+str(list(stats.iloc[2:3,1])[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
